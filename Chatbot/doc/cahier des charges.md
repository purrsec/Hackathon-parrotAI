# Cahier des charges - Hackathon Parrot-2
## Interface conversationnelle pour missions autonomes de drones

---

## 1. CONTEXTE DU PROJET

### 1.1 Objectif du hackathon
Cr√©er une interface conversationnelle permettant de contr√¥ler un drone Parrot ANAFI via langage naturel, pour ex√©cuter des missions autonomes sans √©crire de code.

### 1.2 Cas d'usage cibl√©s
- **Inspection de zones** : "Inspecte cette zone en mode photogramm√©trie"
- **Tracking d'objets** : "Suis cet objet en mouvement"
- **Patrouilles automatiques** : "Survole le p√©rim√®tre nord"
- **√âvitement d'obstacles** : Gestion automatique via CV embarqu√©e

### 1.3 Contraintes techniques identifi√©es
- ‚úÖ SDK Parrot mature (Olympe, Ground SDK, Air SDK)
- ‚úÖ CV embarqu√©e disponible (tracking, obstacle avoidance)
- ‚ö†Ô∏è **Contrainte majeure** : D√©veloppement en aveugle
  - Simulateur Sphinx uniquement disponible sur le PC du hackathon
  - N√©cessit√© de coder et tester localement sans acc√®s au simulateur
  - Int√©gration finale √† faire sur place

---

## 2. ARCHITECTURE TECHNIQUE

### 2.1 Principe de d√©couplage
```
[Chatbot Interface] ‚Üê‚Üí [API Standard JSON] ‚Üê‚Üí [Drone Controller]
     (Dev chez toi)                              (Test au hackathon)
```

**Avantage** : D√©veloppement et tests parall√®les sans d√©pendance au simulateur.

### 2.2 Stack technologique

#### Frontend = cahatbot avec tool + acces IA (openAI ou Claude)
- React + TailwindCSS

#### Backend / Contr√¥leur drone
- **Python** : Langage du SDK Olympe
- **Olympe SDK** : Contr√¥le du drone ANAFI
- **FastAPI/Flask** : Serveur API pour recevoir les commandes

#### Environnement de test local
- **Mock Drone** : Simulateur l√©ger en Python reproduisant les r√©ponses Olympe
- Permet de tester toute la logique NLP ‚Üí Commandes sans le vrai simulateur

---

## 3. SP√âCIFICATIONS FONCTIONNELLES

### 3.1 Flux utilisateur
1. **Utilisateur** tape une commande en fran√ßais : 
   - "D√©colle et survole la zone nord"
   - "Suis cette personne"
   - "Inspecte ce b√¢timent en prenant des photos"

2. **IA (Claude ou OpenAI)** parse et structure la commande :
   ```json
   {
     "intent": "patrol",
     "action": "takeoff_and_move",
     "parameters": {
       "zone": "north",
       "altitude": 10,
       "speed": 2
     }
   }
   ```

3. **Backend** traduit en appels Olympe SDK :
   ```python
   drone.takeoff()
   drone.move_to(lat, lon, altitude)
   ```

4. **Retour visuel** : Statut en temps r√©el dans l'interface
   - Position GPS
   - Altitude
   - Batterie
   - √âtat de la mission
   - Stream vid√©o

### 3.2 Commandes prioritaires (MVP) A v√©rifier si c'est les vraies commandes Olympe

| Commande utilisateur | Intent | API Olympe | Complexit√© |
|---------------------|--------|------------|-----------|
| "D√©colle" | `takeoff` | `drone.takeoff()` | ‚≠ê Facile |
| "Atterris" | `land` | `drone.land()` | ‚≠ê Facile |
| "Va au point X,Y" | `move_to` | `drone.move_to(lat, lon, alt)` | ‚≠ê‚≠ê Moyen |
| "Suis cet objet" | `track_object` | Mode Cameraman SDK | ‚≠ê‚≠ê‚≠ê Difficile |
| "Inspecte cette zone" | `inspect_area` | Flight Plan photogrammetry | ‚≠ê‚≠ê‚≠ê Difficile |
| "Retourne √† la base" | `return_home` | `drone.return_to_home()` | ‚≠ê Facile |

### 3.3 Gestion des erreurs
- **Commande ambigu√´** : L'IA demande des pr√©cisions
  - User : "Va l√†-bas"
  - Bot : "Peux-tu pr√©ciser les coordonn√©es ou une direction (nord/sud) ?"
  
- **Erreur drone** : Affichage explicite
  - Batterie faible (<20%)
  - GPS perdu
  - Obstacle d√©tect√©

---

## 4. PROTOCOLE DE COMMUNICATION

### 4.1 Format JSON standardis√©

#### Commande ‚Üí Drone
```json
{
  "id": "cmd_001",
  "timestamp": "2025-11-07T14:30:00Z",
  "action": "takeoff",
  "parameters": {
    "altitude": 10
  }
}
```

#### R√©ponse Drone ‚Üí Interface
```json
{
  "id": "cmd_001",
  "status": "success|in_progress|error",
  "data": {
    "altitude": 10.2,
    "battery": 85,
    "gps": {"lat": 48.8566, "lon": 2.3522}
  },
  "message": "D√©collage r√©ussi"
}
```

### 4.2 Actions support√©es (API Contract)

```typescript
interface DroneAction {
  // Mouvements de base
  takeoff: {}
  land: {}
  move_to: { lat: number, lon: number, altitude: number }
  move_relative: { forward: number, right: number, up: number }
  
  // Missions avanc√©es
  start_tracking: { target_type: "person" | "vehicle" | "object" }
  start_inspection: { area: Polygon, pattern: "grid" | "orbit" }
  start_patrol: { waypoints: [lat, lon][] }
  
  // Contr√¥le
  pause: {}
  resume: {}
  return_home: {}
  emergency_stop: {}
}
```

---

## 5. PLAN DE D√âVELOPPEMENT

### 5.1 Chez toi (Avant le hackathon)

#### Jour 1 : Setup + Mock
- [ ] Cr√©er l'architecture de projet
- [ ] D√©velopper le **Mock Drone** Python
  - Simule les r√©ponses Olympe
  - Logs d√©taill√©s pour debug
- [ ] Cr√©er l'interface React basique
- [ ] Int√©grer l'API Claude pour parsing NLP

#### Jour 2 : Logique m√©tier
- [ ] Impl√©menter le mapping Intent ‚Üí Actions
- [ ] Tester les sc√©narios principaux avec le mock
- [ ] G√©rer les cas d'erreur
- [ ] Ajouter le feedback temps r√©el

#### Jour 3 : Polish
- [ ] Documentation du code
- [ ] Pr√©parer le template Olympe (structure pr√™te √† remplir)
- [ ] Tests de charge (latence IA, commandes rapides)

### 5.2 Au hackathon (Jour J)

#### Phase 1 : Int√©gration (2h)
1. Cloner le projet sur leur PC
2. Installer Olympe + Sphinx
3. Remplacer `mock_drone.py` par `olympe_drone.py`
4. Tester `takeoff()` / `land()` sur le simulateur

#### Phase 2 : Validation (2h)
5. Tester chaque commande du MVP
6. Ajuster les param√®tres (vitesse, altitude) selon le simulateur
7. Debugging des edge cases

#### Phase 3 : D√©mo (1h)
8. Pr√©parer le sc√©nario de d√©mo
9. Vid√©o de backup au cas o√π

---

## 6. RISQUES ET MITIGATION

| Risque | Impact | Probabilit√© | Mitigation |
|--------|--------|-------------|-----------|
| Mock trop diff√©rent d'Olympe | ‚ö†Ô∏è Moyen | Moyen | Consulter la doc Olympe pour alignement |
| Latence API Claude | ‚ö†Ô∏è Faible | Faible | Cache des commandes fr√©quentes |
| Simulateur bugu√© au hackathon | üî¥ √âlev√© | Faible | Vid√©o de d√©mo avec mock en backup |
| Parsing NLP impr√©cis | ‚ö†Ô∏è Moyen | Moyen | Fallback sur commandes structur√©es |
| Pas assez de temps d'int√©gration | üî¥ √âlev√© | Moyen | **Architecture d√©coupl√©e = priorit√© #1** |

---

## 7. CRIT√àRES DE SUCC√àS

### MVP (Minimum Viable Product)
‚úÖ Chatbot comprend 5 commandes de base  
‚úÖ Drone d√©colle/atterrit via commande vocale  
‚úÖ Affichage du statut en temps r√©el  
‚úÖ Gestion d'1 cas d'erreur (ex: batterie faible)

### Version id√©ale (si temps)
‚úÖ Tracking d'objet fonctionnel  
‚úÖ Inspection de zone (photogramm√©trie)  
‚úÖ Stream vid√©o dans l'interface  
‚úÖ Historique des commandes avec replay

---

## 8. LIVRABLES ATTENDUS

### Code
- Repository GitHub avec :
  - `/chatbot-interface` (React)
  - `/drone-controller` (Python Mock + Template Olympe)
  - `/docs` (Ce cahier des charges + API doc)
  - `README.md` avec proc√©dure d'installation

### Documentation
- Guide d'int√©gration Olympe (5 min setup)
- Vid√©o d√©mo du mock (fallback)
- Pr√©sentation pitch (3 slides max)

### Au hackathon
- D√©mo live de 5 min
- Code fonctionnel sur leur simulateur

---

## 9. QUESTIONS EN SUSPENS

- [ ] Quelle infrastructure OVHcloud utiliser pour h√©berger l'API ? (Voir roadmap fournie)
- [ ] Besoin de compute GPU pour le parsing NLP ou CPU suffit ?
- [ ] Stream vid√©o n√©cessaire dans le MVP ou nice-to-have ?
- [ ] Acc√®s WiFi/r√©seau au hackathon pour les appels API Claude ?

---

## 10. NEXT STEPS IMM√âDIATS

1. **Valider ce cahier des charges**
2. **Choisir la stack** : 
   - React + FastAPI ?
   - Autre combo ?
3. **Je te code le starter kit** :
   - Mock Drone Python
   - Interface React + Claude API
   - Template Olympe
4. **Tu testes en local** avec le mock
5. **Int√©gration finale** au hackathon

---

**Pr√™t √† d√©marrer ?** Dis-moi si tu valides cette approche ou si tu veux ajuster des points ! üöÄ